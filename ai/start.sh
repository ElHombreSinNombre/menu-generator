
ollama create llama3_local -f /app/models/Modelfile
ollama serve